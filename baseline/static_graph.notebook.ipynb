{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STATIC GRAPH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.contrib.layers import xavier_initializer as xinit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x] Mask padding while calculating loss\n",
    "- [x] Deal with variable length input sequence\n",
    "- [ ] Add `EOS` (end of sentence) token to data (target sequence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data_utils\n",
    "metadata, idx_q, idx_a = data_utils.load_data('../data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add special symbol\n",
    "i2w = metadata['idx2w'] + ['GO'] + ['EOS']\n",
    "w2i = metadata['w2idx']\n",
    "w2i['GO'] = len(i2w)-2\n",
    "w2i['EOS'] = len(i2w)-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "B = 8\n",
    "L = len(idx_q[0])\n",
    "vocab_size = len(i2w)\n",
    "enc_hdim = 250\n",
    "dec_hdim = enc_hdim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inputs = tf.placeholder(tf.int32, shape=[B,L], name='inputs')\n",
    "targets = tf.placeholder(tf.int32, shape=[B,L], name='targets')\n",
    "decoder_inputs = tf.concat(\n",
    "    values=[tf.constant(w2i['GO'], dtype=tf.int32, shape=[B,1]), targets[:, 1:]],\n",
    "    axis=1)\n",
    "training = tf.placeholder(tf.bool, name='is_training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_inputs, targets, inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequence Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Encoder\n",
    "#  Get sequence lengths\n",
    "def seq_len(t):\n",
    "    return tf.reduce_sum(tf.cast(t>0, tf.int32), axis=1)\n",
    "\n",
    "enc_seq_len = seq_len(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Decoder\n",
    "#   Mask targets\n",
    "#    to be applied to cross entropy loss\n",
    "padding_mask = tf.cast(targets > 0, tf.float32 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "emb_mat = tf.get_variable('emb', shape=[vocab_size, enc_hdim], dtype=tf.float32, \n",
    "                         initializer=xinit())\n",
    "emb_enc_inputs = tf.nn.embedding_lookup(emb_mat, inputs)\n",
    "emb_dec_inputs = tf.nn.embedding_lookup(emb_mat, decoder_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope('encoder'):\n",
    "    encoder_cell = tf.contrib.rnn.LSTMCell(num_units=enc_hdim)\n",
    "    encoder_outputs, context = tf.nn.dynamic_rnn(cell=encoder_cell, # encoder cell\n",
    "                          inputs=emb_enc_inputs, # embedding input sequences\n",
    "                          sequence_length=enc_seq_len, # lengths of sequences\n",
    "                          initial_state = # zero state of cell\n",
    "                                encoder_cell.zero_state(batch_size=B, dtype=tf.float32)\n",
    "                         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# inference - custom rnn\n",
    "def inference_decoder(cell, state):\n",
    "    #tf.get_variable_scope().reuse_variables()\n",
    "    with tf.variable_scope('decoder_1'):\n",
    "        dec_outputs = []\n",
    "        input_ = tf.constant(w2i['GO'], dtype=tf.int32, shape=[B,])\n",
    "        input_ = tf.nn.embedding_lookup(emb_mat, input_)\n",
    "        \n",
    "        for i in range(L):\n",
    "            decoder_output, state = cell(input_, state)\n",
    "            dec_outputs.append(decoder_output)\n",
    "            input_ = decoder_output\n",
    "\n",
    "    return tf.stack(dec_outputs), None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope('decoder') as scope:\n",
    "    decoder_cell = tf.contrib.rnn.LSTMCell(num_units=dec_hdim)\n",
    "    \n",
    "    decoder_outputs, _ = tf.nn.dynamic_rnn(cell=decoder_cell,\n",
    "                          inputs=emb_dec_inputs, \n",
    "                          initial_state= context,\n",
    "                          scope='decoder_1')\n",
    "                         \n",
    "    tf.get_variable_scope().reuse_variables()\n",
    "    \n",
    "    decoder_outputs_inf, _ = inference_decoder(decoder_cell, context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logits and Probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Wo = tf.get_variable('Wo', shape=[dec_hdim, vocab_size], dtype=tf.float32, \n",
    "                         initializer=xinit())\n",
    "bo = tf.get_variable('bo', shape=[vocab_size], dtype=tf.float32, \n",
    "                         initializer=xinit())\n",
    "proj_outputs = tf.matmul(tf.reshape(decoder_outputs, [B*L, dec_hdim]), Wo) + bo\n",
    "proj_outputs_inf = tf.matmul(tf.reshape(decoder_outputs_inf, [B*L, dec_hdim]), Wo) + bo\n",
    "\n",
    "logits = tf.cond(tf.random_normal(shape=()) > 0.,\n",
    "    lambda : tf.reshape(proj_outputs, [B, L, vocab_size]),\n",
    "    lambda : tf.reshape(proj_outputs_inf, [B, L, vocab_size])\n",
    "                )\n",
    "probs = tf.nn.softmax(tf.reshape(proj_outputs_inf, [B, L, vocab_size]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "    logits =  logits,\n",
    "    labels = targets)\n",
    "# apply mask\n",
    "masked_cross_entropy = cross_entropy * padding_mask\n",
    "# average across sequence, batch\n",
    "loss = tf.reduce_mean(cross_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizatin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.01)\n",
    "train_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction = tf.argmax(probs, axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "config = tf.ConfigProto(allow_soft_placement = True)\n",
    "sess = tf.InteractiveSession(config = config)\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_epochs = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(num_epochs):\n",
    "    avg_loss = 0.\n",
    "    for j in range(len(idx_q)//B):\n",
    "        _, loss_v = sess.run([train_op, loss], feed_dict = {\n",
    "            inputs : idx_q[j*B:(j+1)*B],\n",
    "            targets : idx_a[j*B:(j+1)*B]\n",
    "        })\n",
    "        avg_loss += loss_v\n",
    "        if j and j%30==0:\n",
    "            print('{}.{} : {}'.format(i,j,avg_loss/30))\n",
    "            avg_loss = 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare CE and masked CE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ce, mce = sess.run([cross_entropy, masked_cross_entropy], feed_dict = {\n",
    "            inputs : idx_q[j*B:(j+1)*B],\n",
    "            targets : idx_a[j*B:(j+1)*B]\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ce[0], mce[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "j = 117\n",
    "pred_v = sess.run(prediction, feed_dict = {\n",
    "            inputs : idx_q[j*B:(j+1)*B],\n",
    "            #targets : idx_a[j*B:(j+1)*B]\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_v[0], idx_a[j*B:(j+1)*B][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def arr2sent(arr):\n",
    "    return ' '.join([i2w[item] for item in arr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(B):\n",
    "    print(arr2sent(pred_v[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr2sent( idx_a[j*B:(j+1)*B][11])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
