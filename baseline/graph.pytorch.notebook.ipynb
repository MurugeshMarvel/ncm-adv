{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STATIC GRAPH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torch.autograd import Variable\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import data_utils\n",
    "metadata, idx_q, idx_a = data_utils.load_data('../data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add special symbol\n",
    "i2w = metadata['idx2w'] + ['GO']\n",
    "w2i = metadata['w2idx']\n",
    "w2i['GO'] = len(i2w)-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "L = len(idx_q[0])\n",
    "vocab_size = len(i2w)\n",
    "hidden_size = 256\n",
    "dataset_size = len(idx_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Config:\n",
    "    pass\n",
    "\n",
    "config = Config()\n",
    "config.printsize = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "267518"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(idx_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[179738 229898 156748 238258 219448 108679  41799 165108 181828 100319\n",
      " 127489 121219 169288  58519 125399 117039 250798   2089  52249  81509\n",
      "  43889 154658  91959 148388 265428 114949  25079  16719  66879  77329\n",
      " 112859 257068 240348 150478  83599 244528 242438  94049 171378 225718\n",
      "      0 194368  75239 183918  39709  37619  12539 146298  31349 234078\n",
      " 192278 110769 177648 129579 223628  71059 106589 211088 208998 221538\n",
      " 167198 102409 248708  85689  48069 186008  54339  50159  60609 173468\n",
      " 142118 204818 104499 254978  27169 190188 196458  73149 227808 163018\n",
      " 131669 213178  62699 198548 246618 188098  56429 160928 231988  64789\n",
      " 252888 137938 259158  45979 119129   8359  10449 123309  68969 236168\n",
      " 152568 202728  18809  14629 135848 206908   6269 217358 158838  35529\n",
      " 261248 263338  22989  79419 215268  87779 140028 144208 133759  20899\n",
      " 200638  98229   4179  89869  29259  33439 175558  96139]\n",
      "(128, 21)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "x = np.arange(batch_size)\n",
    "np.random.shuffle(x)\n",
    "x = x * dataset_size//batch_size\n",
    "print(x)\n",
    "print(idx_q[x].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def initial_state(batch_size, hidden_size):\n",
    "    state = torch.zeros([batch_size, hidden_size])\n",
    "    return Variable(state.cuda())\n",
    "\n",
    "def psize(name, variable):\n",
    "    if config.printsize:\n",
    "        print(name, variable.size(), type(variable.data))\n",
    "        \n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_size):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        self.vocab_size = vocab_size\n",
    "        self.hidden_size = hidden_size\n",
    "                \n",
    "        self.embed = nn.Embedding(vocab_size, hidden_size)\n",
    "        self.encode = nn.LSTMCell(hidden_size, hidden_size)\n",
    "            \n",
    "    def forward(self, enc_inputs, hidden, batch_size):\n",
    "        input_length = enc_inputs.size()[0]\n",
    "        psize('enc_inputs', enc_inputs)\n",
    "        enc_embeddings = self.embed(enc_inputs)\n",
    "        psize('enc_embeddings', enc_embeddings)\n",
    "        enc_embeddings = enc_embeddings.view(input_length, \n",
    "                                            batch_size, \n",
    "                                            hidden_size)            #LxBxH       \n",
    "                \n",
    "        psize('enc_embeddings', enc_embeddings)        \n",
    "        hidden, cell_state = hidden\n",
    "        for i in range(enc_embeddings.size()[0]):\n",
    "            hidden, cell_state = self.encode(enc_embeddings[i], (hidden, cell_state))\n",
    "            \n",
    "        return hidden, cell_state\n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_size):\n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        self.vocab_size = vocab_size\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.decode = nn.LSTMCell(hidden_size, hidden_size)\n",
    "        self.embed = nn.Embedding(vocab_size, hidden_size)\n",
    "        self.project = nn.Linear(hidden_size, vocab_size)\n",
    "        \n",
    "    def forward(self, outputs, hidden, batch_size):\n",
    "        length = outputs.size()[0]\n",
    "        psize('hidden', hidden[0]), psize('hidden', hidden[1])\n",
    "        predicted_outputs = []\n",
    "    \n",
    "        dec_embeddings = self.embed(outputs).view(length,\n",
    "                                                 batch_size,\n",
    "                                                 hidden_size)           #LxBxH\n",
    "    \n",
    "        GO = torch.LongTensor([w2i['GO']] * batch_size).cuda()            \n",
    "        GO = Variable(GO)\n",
    "        psize('GO', GO)\n",
    "        dec_input = GO\n",
    "        hidden, cell_state = hidden\n",
    "        for i in range(length):\n",
    "            psize('\\tdec_input', dec_input)\n",
    "            dec_input_emb = self.embed(dec_input)\n",
    "            psize('\\tdec_input_emb', dec_input_emb)\n",
    "\n",
    "            hidden, cell_state = self.decode(dec_input_emb, (hidden, cell_state))\n",
    "            predicted_outputs.append(hidden)\n",
    "\n",
    "            topv, topi = self.project(F.log_softmax(hidden)).topk(1)\n",
    "            psize('\\ttopi', topi)\n",
    "            dec_input = topi.squeeze(1)\n",
    "            \n",
    "        predicted_outputs = torch.stack(predicted_outputs).squeeze(1)\n",
    "        psize('predicted_outputs', predicted_outputs)\n",
    "              \n",
    "        predicted_outputs = self.project(predicted_outputs.view(length*batch_size, hidden_size))\n",
    "        psize('predicted_outputs', predicted_outputs)\n",
    "        predicted_outputs = predicted_outputs.view(length, batch_size, vocab_size)\n",
    "        psize('predicted_outputs', predicted_outputs)\n",
    "\n",
    "        return predicted_outputs\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "from tqdm import tqdm\n",
    "def train_epochs(epochs, encoder, decoder, eoptim, doptim, criterion, print_every=1):\n",
    "    encoder.train()\n",
    "    decoder.train()\n",
    "    losses = []\n",
    "    config.printsize = True\n",
    "\n",
    "    for epoch in tqdm(range(epochs+1)):\n",
    "        loss = train(encoder, decoder, eoptim, doptim, criterion, idx_q, idx_a,\n",
    "                    print_every=print_every*100)    \n",
    "        if epoch % print_every == 0:\n",
    "            losses.append(loss)\n",
    "            print('{} - loss: {}'.format(epoch, loss))\n",
    "\n",
    "        \n",
    "def train(encoder, decoder, eoptim, doptim, criterion, question_ids, answer_ids, print_every=100):\n",
    "    input_length = len(question_ids[0])\n",
    "    dataset_size = len(idx_q)\n",
    "    batch_count  = dataset_size//batch_size\n",
    "    for batch_index in range(batch_count):\n",
    "        #l,r = batch_index * batch_size, (batch_index + 1) * batch_size\n",
    "        import numpy as np\n",
    "        indices = np.arange(batch_size)\n",
    "        np.random.shuffle(indices)\n",
    "        indices = indices * batch_count\n",
    "        \n",
    "        question_id, answer_id = question_ids[indices], answer_ids[indices]\n",
    "        _batch_size = len(question_id)\n",
    "        if _batch_size != batch_size:\n",
    "            print('breaking because batch sizes do not match')\n",
    "            break\n",
    "\n",
    "        data = Variable(torch.from_numpy(question_id).long().cuda().t())\n",
    "        target = Variable(torch.from_numpy(answer_id).long().cuda().t())\n",
    "\n",
    "        eoptim.zero_grad(), doptim.zero_grad()    \n",
    "        initial_hidden = initial_state(batch_size, hidden_size).cuda(), initial_state(batch_size, hidden_size).cuda()\n",
    "        \n",
    "        encoder_output = encoder(data, initial_hidden, _batch_size)\n",
    "        decoder_output = decoder(target, encoder_output, _batch_size)\n",
    "        loss = 0\n",
    "        for i in range(input_length):\n",
    "            logits = F.log_softmax(decoder_output[i])\n",
    "            loss += criterion(logits, target[i])    \n",
    "            \n",
    "        loss.backward()\n",
    "        eoptim.step(), doptim.step()\n",
    "        config.printsize = False\n",
    "        \n",
    "        if batch_index % print_every == 0:\n",
    "            print('\\t{} - loss: {}'.format(batch_index, loss.data[0]))\n",
    "        \n",
    "    return loss.data[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder = Encoder(vocab_size, hidden_size)\n",
    "decoder = Decoder(vocab_size, hidden_size)\n",
    "\n",
    "encoder.cuda()\n",
    "decoder.cuda()\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "eoptim = optim.SGD(encoder.parameters(), lr=0.1, momentum=0.1)\n",
    "doptim = optim.SGD(decoder.parameters(), lr=0.1, momentum=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/11 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enc_inputs torch.Size([21, 128]) <class 'torch.cuda.LongTensor'>\n",
      "enc_embeddings torch.Size([21, 128, 256]) <class 'torch.cuda.FloatTensor'>\n",
      "enc_embeddings torch.Size([21, 128, 256]) <class 'torch.cuda.FloatTensor'>\n",
      "hidden torch.Size([128, 256]) <class 'torch.cuda.FloatTensor'>\n",
      "hidden torch.Size([128, 256]) <class 'torch.cuda.FloatTensor'>\n",
      "GO torch.Size([128]) <class 'torch.cuda.LongTensor'>\n",
      "\tdec_input torch.Size([128]) <class 'torch.cuda.LongTensor'>\n",
      "\tdec_input_emb torch.Size([128, 256]) <class 'torch.cuda.FloatTensor'>\n",
      "\ttopi torch.Size([128, 1]) <class 'torch.cuda.LongTensor'>\n",
      "\tdec_input torch.Size([128]) <class 'torch.cuda.LongTensor'>\n",
      "\tdec_input_emb torch.Size([128, 256]) <class 'torch.cuda.FloatTensor'>\n",
      "\ttopi torch.Size([128, 1]) <class 'torch.cuda.LongTensor'>\n",
      "\tdec_input torch.Size([128]) <class 'torch.cuda.LongTensor'>\n",
      "\tdec_input_emb torch.Size([128, 256]) <class 'torch.cuda.FloatTensor'>\n",
      "\ttopi torch.Size([128, 1]) <class 'torch.cuda.LongTensor'>\n",
      "\tdec_input torch.Size([128]) <class 'torch.cuda.LongTensor'>\n",
      "\tdec_input_emb torch.Size([128, 256]) <class 'torch.cuda.FloatTensor'>\n",
      "\ttopi torch.Size([128, 1]) <class 'torch.cuda.LongTensor'>\n",
      "\tdec_input torch.Size([128]) <class 'torch.cuda.LongTensor'>\n",
      "\tdec_input_emb torch.Size([128, 256]) <class 'torch.cuda.FloatTensor'>\n",
      "\ttopi torch.Size([128, 1]) <class 'torch.cuda.LongTensor'>\n",
      "\tdec_input torch.Size([128]) <class 'torch.cuda.LongTensor'>\n",
      "\tdec_input_emb torch.Size([128, 256]) <class 'torch.cuda.FloatTensor'>\n",
      "\ttopi torch.Size([128, 1]) <class 'torch.cuda.LongTensor'>\n",
      "\tdec_input torch.Size([128]) <class 'torch.cuda.LongTensor'>\n",
      "\tdec_input_emb torch.Size([128, 256]) <class 'torch.cuda.FloatTensor'>\n",
      "\ttopi torch.Size([128, 1]) <class 'torch.cuda.LongTensor'>\n",
      "\tdec_input torch.Size([128]) <class 'torch.cuda.LongTensor'>\n",
      "\tdec_input_emb torch.Size([128, 256]) <class 'torch.cuda.FloatTensor'>\n",
      "\ttopi torch.Size([128, 1]) <class 'torch.cuda.LongTensor'>\n",
      "\tdec_input torch.Size([128]) <class 'torch.cuda.LongTensor'>\n",
      "\tdec_input_emb torch.Size([128, 256]) <class 'torch.cuda.FloatTensor'>\n",
      "\ttopi torch.Size([128, 1]) <class 'torch.cuda.LongTensor'>\n",
      "\tdec_input torch.Size([128]) <class 'torch.cuda.LongTensor'>\n",
      "\tdec_input_emb torch.Size([128, 256]) <class 'torch.cuda.FloatTensor'>\n",
      "\ttopi torch.Size([128, 1]) <class 'torch.cuda.LongTensor'>\n",
      "\tdec_input torch.Size([128]) <class 'torch.cuda.LongTensor'>\n",
      "\tdec_input_emb torch.Size([128, 256]) <class 'torch.cuda.FloatTensor'>\n",
      "\ttopi torch.Size([128, 1]) <class 'torch.cuda.LongTensor'>\n",
      "\tdec_input torch.Size([128]) <class 'torch.cuda.LongTensor'>\n",
      "\tdec_input_emb torch.Size([128, 256]) <class 'torch.cuda.FloatTensor'>\n",
      "\ttopi torch.Size([128, 1]) <class 'torch.cuda.LongTensor'>\n",
      "\tdec_input torch.Size([128]) <class 'torch.cuda.LongTensor'>\n",
      "\tdec_input_emb torch.Size([128, 256]) <class 'torch.cuda.FloatTensor'>\n",
      "\ttopi torch.Size([128, 1]) <class 'torch.cuda.LongTensor'>\n",
      "\tdec_input torch.Size([128]) <class 'torch.cuda.LongTensor'>\n",
      "\tdec_input_emb torch.Size([128, 256]) <class 'torch.cuda.FloatTensor'>\n",
      "\ttopi torch.Size([128, 1]) <class 'torch.cuda.LongTensor'>\n",
      "\tdec_input torch.Size([128]) <class 'torch.cuda.LongTensor'>\n",
      "\tdec_input_emb torch.Size([128, 256]) <class 'torch.cuda.FloatTensor'>\n",
      "\ttopi torch.Size([128, 1]) <class 'torch.cuda.LongTensor'>\n",
      "\tdec_input torch.Size([128]) <class 'torch.cuda.LongTensor'>\n",
      "\tdec_input_emb torch.Size([128, 256]) <class 'torch.cuda.FloatTensor'>\n",
      "\ttopi torch.Size([128, 1]) <class 'torch.cuda.LongTensor'>\n",
      "\tdec_input torch.Size([128]) <class 'torch.cuda.LongTensor'>\n",
      "\tdec_input_emb torch.Size([128, 256]) <class 'torch.cuda.FloatTensor'>\n",
      "\ttopi torch.Size([128, 1]) <class 'torch.cuda.LongTensor'>\n",
      "\tdec_input torch.Size([128]) <class 'torch.cuda.LongTensor'>\n",
      "\tdec_input_emb torch.Size([128, 256]) <class 'torch.cuda.FloatTensor'>\n",
      "\ttopi torch.Size([128, 1]) <class 'torch.cuda.LongTensor'>\n",
      "\tdec_input torch.Size([128]) <class 'torch.cuda.LongTensor'>\n",
      "\tdec_input_emb torch.Size([128, 256]) <class 'torch.cuda.FloatTensor'>\n",
      "\ttopi torch.Size([128, 1]) <class 'torch.cuda.LongTensor'>\n",
      "\tdec_input torch.Size([128]) <class 'torch.cuda.LongTensor'>\n",
      "\tdec_input_emb torch.Size([128, 256]) <class 'torch.cuda.FloatTensor'>\n",
      "\ttopi torch.Size([128, 1]) <class 'torch.cuda.LongTensor'>\n",
      "\tdec_input torch.Size([128]) <class 'torch.cuda.LongTensor'>\n",
      "\tdec_input_emb torch.Size([128, 256]) <class 'torch.cuda.FloatTensor'>\n",
      "\ttopi torch.Size([128, 1]) <class 'torch.cuda.LongTensor'>\n",
      "predicted_outputs torch.Size([21, 128, 256]) <class 'torch.cuda.FloatTensor'>\n",
      "predicted_outputs torch.Size([2688, 6005]) <class 'torch.cuda.FloatTensor'>\n",
      "predicted_outputs torch.Size([21, 128, 6005]) <class 'torch.cuda.FloatTensor'>\n",
      "\t0 - loss: 182.9229736328125\n",
      "\t100 - loss: 71.56849670410156\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-91808252fcff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_epochs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meoptim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoptim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-14-857c2bff2705>\u001b[0m in \u001b[0;36mtrain_epochs\u001b[0;34m(epochs, encoder, decoder, eoptim, doptim, criterion, print_every)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         loss = train(encoder, decoder, eoptim, doptim, criterion, idx_q, idx_a,\n\u001b[0;32m---> 11\u001b[0;31m                     print_every=print_every*100)    \n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mprint_every\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-857c2bff2705>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(encoder, decoder, eoptim, doptim, criterion, question_ids, answer_ids, print_every)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mencoder_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_hidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_batch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mdecoder_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_batch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/paarulakan/environments/python/pytorch-py35/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-23-30da90a7f90a>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, outputs, hidden, batch_size)\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0mpsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\tdec_input_emb'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_input_emb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdec_input_emb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m             \u001b[0mpredicted_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/paarulakan/environments/python/pytorch-py35/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/paarulakan/environments/python/pytorch-py35/lib/python3.5/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    497\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight_ih\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight_hh\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 499\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias_ih\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias_hh\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    500\u001b[0m         )\n\u001b[1;32m    501\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/paarulakan/environments/python/pytorch-py35/lib/python3.5/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mLSTMCell\u001b[0;34m(input, hidden, w_ih, w_hh, b_ih, b_hh)\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mingate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mingate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mforgetgate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mforgetgate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mcellgate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcellgate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0moutgate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutgate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/paarulakan/environments/python/pytorch-py35/lib/python3.5/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mtanh\u001b[0;34m(input)\u001b[0m\n\u001b[1;32m    420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 422\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/paarulakan/environments/python/pytorch-py35/lib/python3.5/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36mtanh\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 348\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mTanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtanh_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/paarulakan/environments/python/pytorch-py35/lib/python3.5/site-packages/torch/autograd/_functions/pointwise.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, i)\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_for_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_epochs(10, encoder, decoder, eoptim, doptim, criterion,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "torch.save(encoder.state_dict(), 'graph.pytorch.encoder.pth')\n",
    "torch.save(decoder.state_dict(), 'graph.pytorch.decoder.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder_test = Encoder(vocab_size, hidden_size)\n",
    "decoder_test = Decoder(vocab_size, hidden_size)\n",
    "encoder_test.cuda()\n",
    "decoder_test.cuda()\n",
    "encoder_test.load_state_dict(torch.load('graph.pytorch.encoder.pth'))\n",
    "decoder_test.load_state_dict(torch.load('graph.pytorch.decoder.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enc_inputs torch.Size([21]) <class 'torch.cuda.LongTensor'>\n",
      "enc_embeddings torch.Size([21, 256]) <class 'torch.cuda.FloatTensor'>\n",
      "enc_embeddings torch.Size([21, 1, 256]) <class 'torch.cuda.FloatTensor'>\n",
      "hidden torch.Size([1, 256]) <class 'torch.cuda.FloatTensor'>\n",
      "hidden torch.Size([1, 256]) <class 'torch.cuda.FloatTensor'>\n",
      "GO torch.Size([1]) <class 'torch.cuda.LongTensor'>\n",
      "GO_emd torch.Size([1, 256]) <class 'torch.cuda.FloatTensor'>\n",
      "predicted_outputs torch.Size([21, 256]) <class 'torch.cuda.FloatTensor'>\n",
      "predicted_outputs torch.Size([21, 6005]) <class 'torch.cuda.FloatTensor'>\n"
     ]
    }
   ],
   "source": [
    "batch = 0\n",
    "l, r = batch * B, (batch + 1) * B\n",
    "test_q, test_a = idx_q[0], idx_a[0]\n",
    "\n",
    "encoder_test.eval()\n",
    "decoder_test.eval()\n",
    "\n",
    "test_q = Variable(torch.from_numpy(test_q).long().cuda())\n",
    "test_a = Variable(torch.from_numpy(test_a).long().cuda())\n",
    "\n",
    "config.printsize = True\n",
    "batch_size = 1\n",
    "hidden = initial_state(batch_size, hidden_size).cuda(), initial_state(batch_size, hidden_size).cuda()\n",
    "predictions = decoder_test.predict(test_a, encoder_test(test_q, hidden, 1), 1)\n",
    "predictions = predictions.squeeze(1)\n",
    "predictions = F.log_softmax(predictions).max(1)[1].squeeze(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def arr2sent(arr):\n",
    "    return ' '.join([i2w[item] for item in arr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "  131\n",
      "  289\n",
      "   90\n",
      " 5149\n",
      "   75\n",
      "   36\n",
      "   46\n",
      "   25\n",
      "   25\n",
      "   25\n",
      "  141\n",
      "   91\n",
      "  213\n",
      "   25\n",
      "   25\n",
      "   60\n",
      "   20\n",
      "  273\n",
      "   14\n",
      "   14\n",
      "  122\n",
      "[torch.cuda.LongTensor of size 21 (GPU 0)]\n",
      "\n",
      "yeah cool great parade she all from me me me does need things me me thats not makes that that oh\n",
      "yeah dude i would definitely consider a daniel unk super reliable and they are just bad ass EOS _ _ _\n"
     ]
    }
   ],
   "source": [
    "print(predictions)\n",
    "print(arr2sent(predictions.cpu().data.numpy()))\n",
    "print(arr2sent(test_a.cpu().data.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_epochs_(epochs, encoder, decoder, eoptim, doptim, criterion, print_every=1, validate_every=10):\n",
    "    encoder.train()\n",
    "    decoder.train()\n",
    "    losses = []\n",
    "    config.printsize = True\n",
    "\n",
    "    for epoch in tqdm(range(epochs+1)):\n",
    "        print('--- epoch: {} ---'.format(epoch))\n",
    "        loss = train(encoder, decoder, eoptim, doptim, criterion, idx_q, idx_a,\n",
    "                    print_every=print_every*1000)    \n",
    "        if epoch % print_every == 0:\n",
    "            losses.append(loss)\n",
    "            print('{} - loss: {}'.format(epoch, loss))\n",
    "\n",
    "        torch.save(encoder.state_dict(), 'graph.pytorch.encoder.pth')\n",
    "        torch.save(decoder.state_dict(), 'graph.pytorch.decoder.pth')\n",
    "\n",
    "        encoder_test.load_state_dict(torch.load('graph.pytorch.encoder.pth'))\n",
    "        decoder_test.load_state_dict(torch.load('graph.pytorch.decoder.pth'))\n",
    "\n",
    "        if epoch % validate_every == 0:\n",
    "            test_q, test_a = idx_q[-1], idx_a[-1]\n",
    "\n",
    "            encoder_test.eval()\n",
    "            decoder_test.eval()\n",
    "\n",
    "            test_q = Variable(torch.from_numpy(test_q).long().cuda())\n",
    "            test_a = Variable(torch.from_numpy(test_a).long().cuda())\n",
    "\n",
    "            #config.printsize = True\n",
    "            _batch_size = 1\n",
    "            hidden = initial_state(_batch_size, hidden_size).cuda(), initial_state(_batch_size, hidden_size).cuda()\n",
    "            predictions = decoder_test.predict(test_a, encoder_test(test_q, hidden, _batch_size), _batch_size)\n",
    "            predictions = predictions.squeeze(1)\n",
    "            predictions = F.log_softmax(predictions).max(1)[1].squeeze(1)\n",
    "            \n",
    "            predictions_ = decoder_test(test_a, encoder_test(test_q, hidden, _batch_size), _batch_size)\n",
    "            predictions_ = predictions_.squeeze(1)\n",
    "            predictions_ = F.log_softmax(predictions_).max(1)[1].squeeze(1)\n",
    "\n",
    "            print(arr2sent(predictions.cpu().data.numpy()))\n",
    "            print(arr2sent(predictions_.cpu().data.numpy()))\n",
    "            print(arr2sent(test_a.cpu().data.numpy()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
