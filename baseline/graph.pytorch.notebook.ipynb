{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STATIC GRAPH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torch.autograd import Variable\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import data_utils\n",
    "metadata, idx_q, idx_a = data_utils.load_data('../data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add special symbol\n",
    "i2w = metadata['idx2w'] + ['GO']\n",
    "w2i = metadata['w2idx']\n",
    "w2i['GO'] = len(i2w)-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "B = 1000\n",
    "L = len(idx_q[0])\n",
    "vocab_size = len(i2w)\n",
    "enc_hdim = 250\n",
    "dec_hdim = enc_hdim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, batch_size, vocab_size, hidden_size, input_size):\n",
    "        super(Model, self).__init__()\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        self.vocab_size = vocab_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.input_size  = input_size\n",
    "        \n",
    "        self.encode = nn.LSTMCell(hidden_size, hidden_size)\n",
    "        self.decode = nn.LSTMCell(hidden_size, hidden_size)\n",
    "        \n",
    "        self.embed = nn.Embedding(vocab_size, hidden_size)\n",
    "        self.project = nn.Linear(hidden_size, vocab_size)\n",
    "        \n",
    "        self.printsize = True\n",
    "        \n",
    "    def initial_state(self):\n",
    "        state = torch.zeros([self.batch_size, self.hidden_size])\n",
    "        return Variable(state)\n",
    "    \n",
    "    def psize(self, name, tensor):\n",
    "        if self.printsize:\n",
    "            print(name, tensor.size())\n",
    "    \n",
    "    def forward(self, enc_inputs, dec_outputs):\n",
    "        self.psize('enc_inputs', enc_inputs)\n",
    "        self.psize('dec_outputs', dec_outputs)\n",
    "\n",
    "        enc_embeddings = self.embed(enc_inputs)                                 #BxLXH <- BxL\n",
    "        dec_embeddings = self.embed(dec_outputs)                                #BXLXH <- BxL\n",
    "        \n",
    "        self.psize('enc_embeddings', enc_embeddings)\n",
    "        self.psize('dec_embeddings', dec_embeddings)\n",
    "        \n",
    "        hidden = cell_state = self.initial_state()                              #BxH\n",
    "        for i in range(enc_embeddings.size()[1]):\n",
    "            hidden, cell_state = self.encode(enc_embeddings[:,i], (hidden, cell_state))\n",
    "        \n",
    "        self.psize('hidden', hidden)\n",
    "        self.psize('cell_state', cell_state)\n",
    "        \n",
    "        predicted_outputs = []\n",
    "        first_input = torch.LongTensor([w2i['GO']] * self.batch_size).view(self.batch_size, self.input_size)\n",
    "        first_input = Variable(first_input).squeeze(1)\n",
    "        self.psize('first_input', first_input)\n",
    "        first_input = self.embed(first_input)\n",
    "        self.psize('first_input', first_input)\n",
    "        hidden, cell_state = self.decode(first_input, (hidden, cell_state))\n",
    "        predicted_outputs.append(hidden)\n",
    "        for i in range(dec_embeddings.size()[1] - 1):\n",
    "            hidden, cell_state = self.decode(dec_embeddings[:,i+1], (hidden, cell_state))\n",
    "            predicted_outputs.append(hidden)\n",
    "            \n",
    "        predicted_outputs = torch.stack(predicted_outputs)\n",
    "        predicted_outputs = predicted_outputs.view(\n",
    "                            self.batch_size * dec_outputs.size()[1], \n",
    "                            self.hidden_size)\n",
    "        self.psize('predicted_outputs', predicted_outputs)\n",
    "        outputs = self.project(predicted_outputs)\n",
    "        self.psize('outputs', outputs)\n",
    "        outputs = outputs.view(self.batch_size, dec_outputs.size()[1], self.vocab_size)\n",
    "        self.psize('outputs', outputs)\n",
    "\n",
    "        outputs = F.log_softmax(outputs).max(2)[1].squeeze(2)\n",
    "        self.psize('outputs', outputs)\n",
    "\n",
    "        return outputs\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epochs, model, question_ids, answer_ids):\n",
    "    model.train()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.1)\n",
    "    for epoch in range(epochs+1):\n",
    "        avg_loss = 0\n",
    "        for batch in range(len(question_ids)//B):\n",
    "            l, r = batch * B, (batch + 1) * B\n",
    "            data = Variable(torch.from_numpy(question_ids[l:r]).long())\n",
    "            target = Variable(torch.from_numpy(answer_ids[l:r]).long())\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            logits = model(data, target)\n",
    "            model.psize('data', data)\n",
    "            model.psize('target', target)\n",
    "            model.psize('logits', logits)\n",
    "            loss = F.nll_loss(logits, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            avg_loss += loss.data[0]\n",
    "            model.printsize = False\n",
    "            \n",
    "            if batch % 20:\n",
    "                print('{}.{} - {}'.format(epoch, batch, avg_loss/20))\n",
    "                avg_loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(B, vocab_size, enc_hdim, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enc_inputs torch.Size([1000, 20])\n",
      "dec_outputs torch.Size([1000, 20])\n",
      "enc_embeddings torch.Size([1000, 20, 250])\n",
      "dec_embeddings torch.Size([1000, 20, 250])\n",
      "hidden torch.Size([1000, 250])\n",
      "cell_state torch.Size([1000, 250])\n",
      "first_input torch.Size([1000])\n",
      "first_input torch.Size([1000, 250])\n",
      "predicted_outputs torch.Size([20000, 250])\n",
      "outputs torch.Size([20000, 8003])\n",
      "outputs torch.Size([1000, 20, 8003])\n",
      "outputs torch.Size([1000, 20])\n",
      "data torch.Size([1000, 20])\n",
      "target torch.Size([1000, 20])\n",
      "logits torch.Size([1000, 20])\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "<class 'torch.LongTensor'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-169-c3eefd453a78>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx_q\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx_a\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-153-0075bc76873d>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epochs, model, question_ids, answer_ids)\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'logits'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/paarulakan/environments/python/pytorch-py35/lib/python3.5/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mnll_loss\u001b[0;34m(input, target, weight, size_average)\u001b[0m\n\u001b[1;32m    475\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Expected 2 or 4 dimensions (got {})'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/paarulakan/environments/python/pytorch-py35/lib/python3.5/site-packages/torch/nn/_functions/thnn/auto.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype2backend\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_for_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mweight_arg_idx\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/paarulakan/environments/python/pytorch-py35/lib/python3.5/site-packages/torch/_thnn/__init__.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: <class 'torch.LongTensor'>"
     ]
    }
   ],
   "source": [
    "train(10, model, idx_q, idx_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Begin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20 : 4.374236321449279\n",
      "0.40 : 2.9668627977371216\n",
      "0.60 : 2.504377770423889\n",
      "0.80 : 1.9982671082019805\n",
      "0.100 : 1.444276547431946\n",
      "0.120 : 1.019878402352333\n",
      "1.20 : 0.7292188316583633\n",
      "1.40 : 0.5727434158325195\n",
      "1.60 : 0.49078361988067626\n",
      "1.80 : 0.4375475347042084\n",
      "1.100 : 0.4037304982542992\n",
      "1.120 : 0.3748603016138077\n",
      "2.20 : 0.35517664849758146\n",
      "2.40 : 0.32739430814981463\n",
      "2.60 : 0.3153625696897507\n",
      "2.80 : 0.3068651154637337\n",
      "2.100 : 0.30491813123226164\n",
      "2.120 : 0.3002783715724945\n",
      "3.20 : 0.3121029630303383\n",
      "3.40 : 0.2952332764863968\n",
      "3.60 : 0.29264847487211226\n",
      "3.80 : 0.2903579115867615\n",
      "3.100 : 0.2914220854640007\n",
      "3.120 : 0.29028379172086716\n",
      "4.20 : 0.3058256059885025\n",
      "4.40 : 0.2903655216097832\n",
      "4.60 : 0.28862053602933885\n",
      "4.80 : 0.2873972564935684\n",
      "4.100 : 0.2889208883047104\n",
      "4.120 : 0.2882304400205612\n",
      "5.20 : 0.3042555972933769\n",
      "5.40 : 0.2887479826807976\n",
      "5.60 : 0.2871220126748085\n",
      "5.80 : 0.2859190031886101\n",
      "5.100 : 0.28765359073877333\n",
      "5.120 : 0.28710009157657623\n",
      "6.20 : 0.3032954305410385\n",
      "6.40 : 0.28779347985982895\n",
      "6.60 : 0.2859370350837708\n",
      "6.80 : 0.28429285138845445\n",
      "6.100 : 0.2864676252007484\n",
      "6.120 : 0.28595814257860186\n",
      "7.20 : 0.3015047624707222\n",
      "7.40 : 0.2860098764300346\n",
      "7.60 : 0.28437033444643023\n",
      "7.80 : 0.28317616879940033\n",
      "7.100 : 0.2848792314529419\n",
      "7.120 : 0.28435947000980377\n",
      "8.20 : 0.30204547494649886\n",
      "8.40 : 0.2852056726813316\n",
      "8.60 : 0.28331569880247115\n",
      "8.80 : 0.2820987835526466\n",
      "8.100 : 0.2834942862391472\n",
      "8.120 : 0.28328265994787216\n",
      "9.20 : 0.29903693348169325\n",
      "9.40 : 0.28365965336561205\n",
      "9.60 : 0.28211608380079267\n",
      "9.80 : 0.28116783648729327\n",
      "9.100 : 0.28281670063734055\n",
      "9.120 : 0.28236148655414584\n"
     ]
    }
   ],
   "source": [
    "for i in range(num_epochs):\n",
    "    avg_loss = 0.\n",
    "    for j in range(len(idx_q)//B):\n",
    "        _, loss_v = sess.run([train_op, loss], feed_dict = {\n",
    "            inputs : idx_q[j*B:(j+1)*B],\n",
    "            targets : idx_a[j*B:(j+1)*B]\n",
    "        })\n",
    "        avg_loss += loss_v\n",
    "        if j and j%20==0:\n",
    "            print('{}.{} : {}'.format(i,j,avg_loss/20))\n",
    "            avg_loss = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "j = 7 \n",
    "pred_v = sess.run(prediction, feed_dict = {\n",
    "            inputs : idx_q[j*B:(j+1)*B],\n",
    "            targets : idx_a[j*B:(j+1)*B]\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  4,  45, 754,  11, 694,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0]),\n",
       " array([1989,   45,  754,   11,  694,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0], dtype=int32))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_v[0], idx_a[j*B:(j+1)*B][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def arr2sent(arr):\n",
    "    return ' '.join([i2w[item] for item in arr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i as if her supporters just accept shes a crook _ _ _ _ _ _ _ _ _ _'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr2sent(pred_v[11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'its as if her supporters just accept shes a crook _ _ _ _ _ _ _ _ _ _'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr2sent( idx_a[j*B:(j+1)*B][11])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
